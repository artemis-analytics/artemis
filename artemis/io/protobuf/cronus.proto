// Copyright Â© Her Majesty the Queen in Right of Canada, as represented
// by the Minister of Statistics Canada, 2019.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
/**
 * Cronus Metastore Model:
 *     Artemis Jobs require:
 *       Dataset
 *          Partition
 *              Files
 *              Histograms
 *              Tables
 *       Menu
 *          Configuration
 *     Artemis Jobs output
 *       Dataset
 *          Partition
 *              Process metadata (must be mergable)
 *              Histograms (must be mergable)
 *              Files (Data)
 *              Logs
 *              Tables (Schemas) (must be mergable)
 *
 *    Each required input/output produces a protobuf serialized, persisted message
 *    these will be stored/retrieved via uuids hrough common stores
 *
 *    The stores provide the name and identifier
 *    of persisted metadata along with additional metadata.
 *    This enables separating the storage of the Artemis job configuration
 *    from the messages required when running an artemis job.
 *
 *    Stores can loaded, information retrieved, and closed.
 *    MenuObject points to a persisted menu, gets loaded
 *    ConfigObject points to a persisted job configuration, get loaded
 *    HistogramCollection points to a persisted or newly created collection
 *    Dataset points to persisted or newly created dataset.
 *    Dataset object is part of the Artemis job.
 *      Access to the partitions, tables, and files is required before, during, after processing
 *
 *    A top-level Artemis Store
 *        DataStore
 *        MenuStore
 *        ConfigurationStore
 *        HistogramStore
 */
syntax = "proto3";
import "google/protobuf/timestamp.proto";

/**
 * Store of Artemis Metadata
 */
message CronusStore {
  string name = 1; 
  string uuid = 2;
  string parent_uuid = 3; // points to a parent store, if empty top-level store
  string address = 4;
  CronusStoreInfo info = 5;
}

/**
 * Absolute location of a persisted store
 * CronusStore can holds 
 * Repeated list of childer stores
 * A store of menus
 * A store of Artemis configurations
 * A store of Artemis datasets
 * Repeated list of CronusObjects -- persisted content addressed files/data
 * Enables multiple top-level stores to be created
 */
message CronusStoreInfo {
  google.protobuf.Timestamp created = 2;
  CronusStoreAuxInfo aux = 3;
  repeated CronusObjectStore child_stores = 4;
}

message CronusStoreAuxInfo {
  string description = 1;
}

message CronusObjectStore {
  string name = 1;
  string uuid = 2;
  string parent_uuid = 3; // points to a parent store, if empty top-level store
  string address = 4;
  CronusObjectStoreInfo info = 5;
}

/**
 * Absolute location of a persisted store
 * CronusStore can holds 
 * Repeated list of childer stores
 * A store of menus
 * A store of Artemis configurations
 * A store of Artemis datasets
 * Repeated list of CronusObjects -- persisted content addressed files/data
 * Enables multiple top-level stores to be created
 */
message CronusObjectStoreInfo {
  google.protobuf.Timestamp created = 2;
  CronusObjectStoreAuxInfo aux = 3;
  repeated CronusObject objects = 5;
}

message CronusObjectStoreAuxInfo {
  string description = 1;
}

/**
 * CronusObject
 * Content Addressed pointer and metadata to persisted data or metadata
 */
message CronusObject {
  string name = 1;
  string uuid = 2;
  string parent_uuid = 3; // Points to parent store, must always be a parent
  string address = 13; // Full path the underlying object resides
  oneof info {
    MenuObjectInfo menu = 4; // Statistical Business Process Model (Protobuf)
    ConfigObjectInfo config = 5; // Artemis Configuration Proto (Protobuf)
    DatasetObjectInfo dataset = 6; // Dataset metadata model (Protobuf)
    HistsObjectInfo hists = 7; // Artemis HistCollection Output Proto (Protobuf)
    JobObjectInfo job = 8; // Artemis Output Process Metadata Proto (Protobuf)
    LogObjectInfo log = 9; // Artemis Log File output (Text File)
    FileObjectInfo file = 11; // Artemis Arrow RecordBatchFile (Arrow)
    TableObjectInfo table = 12; // Artemis Table (Protobuf -- bulk of the metadata relating to a partition)
    TDigestObjectInfo tdigests = 14; // Artemis TDigest Collection
  }
}

/**
 * ArtemisArtifact
 * Holder of metadata that will be persisted
 * Thus needs to interfact with a Dataset to register objects in store
 * Just here as a placeholder
 * 
 * On output
 * hists, jobinfo, logs, partitions, files and tables
 * have already been content addressed and written to storage
 * collect the ArtemisArtifact objects
 * populate the objects into a final dataset
 * Final dataset allows for merging of collections
 * through the content addressed objects
 * CronosObjects all have oneof types of Info objects
 * Info objects are the top-level metadata for an object
 * Info objects hold an Auxilliary Info message also
 */
message ArtemisArtifact {
  // Required to run a job
  // DatasetObject???
  // How to register objects correctly in the Datastore?
  Transform transform = 1; // Everything Artemis needs to run a job on a datafile
  // includes the menu configuration location in store
  // includes the job configuration location in store
  repeated CronusObject input_files = 2; // Needs to know the input data for a given subjob
  // Requires reference to input dataset
  // allows retrieving the dataset information, e.g. the schema
  string dataset_parent_id = 3; // uuid of the dataset ID in store
  // Requires reference to the output child dataset
  // this enables registering the objects into the datastore
  string dataset_child_id = 4;
  // Requires a parent job_id
  string job_parent_id = 5;
  // Requires a job_id
  string child_id = 6;
  // Required to complete a job
  repeated CronusObject partitions = 7;
  // Register the output files
  // Register the output partition schemas
  // Register output file histograms in dataset object
  CronusObject hists = 8; // Histcollection
  // Register output job information in dataset object
  CronusObject jobinfo = 9; // Job process information
  // Register output log file in dataset object
  CronusObject log = 10; // Log file
  // Register output TDigest collection in dataset object
  CronusObject tdigests = 11;
}

/**
 * Stores menu descriptions
 */
message MenuObjectInfo {
  MenuObjectAuxInfo aux = 1;
  google.protobuf.Timestamp created = 2;
}

message MenuObjectAuxInfo {
  string description = 1;
}

/**
 * Stores configuration descriptions
 */
message ConfigObjectInfo {
  ConfigObjectAuxInfo aux = 1;
  google.protobuf.Timestamp created = 2;
}

message ConfigObjectAuxInfo {
  string description = 1;
}

/**
 * Stores histogram descriptions
 */
message HistsObjectInfo {
  HistsObjectAuxInfo aux = 2;
  repeated string keys = 1;
}

message HistsObjectAuxInfo {
  string description = 1;
  map<string,string> meta = 2;
}

/**
 * Stores histogram descriptions
 */
message TDigestObjectInfo {
  TDigestObjectAuxInfo aux = 2;
  repeated string keys = 1;
}

message TDigestObjectAuxInfo {
  string description = 1;
  map<string,string> meta = 2;
}

/**
 * Stores job descriptions
 */
message JobObjectInfo {
  JobObjectAuxInfo aux = 1;
}

message JobObjectAuxInfo {
  string description = 1;
}

/**
 * Stores log descriptions
 */
message LogObjectInfo {
  LogObjectAuxInfo aux = 1;
}

message LogObjectAuxInfo {
  string description = 1;
}

/**
 * Dataset must be registered in Datastore
 * Job artifacts are created from input DatasetObject
 * Ouput job artifacts are collected 
 * and used to populate output DatasetObject
 */
message DatasetObjectInfo {
  DatasetObjectAuxInfo aux = 1;
  Transform transform = 4;
  repeated string partitions = 2;
  int32 job_idx = 13;
  repeated CronusObject jobs = 5;
  repeated CronusObject hists = 6;
  repeated CronusObject logs = 7;
  string storage_location = 8; // Alternative location for data, e.g. files, logs, protos

  repeated CronusObject parents = 9; // Provenance
  repeated CronusObject children = 10;
  repeated CronusObject files = 11;
  repeated CronusObject tables = 12;
  repeated CronusObject tdigests = 14;
}

/**
 * Register the content of a dataset in the object store
 */
message DatasetObjectAuxInfo {
  DataHolding data_holding = 1; // Business Metadata
  DataAsset data_asset = 2; // Technical details 
}

/**
 * Data for accountability purposes
 */
message DataHolding {
  string name = 1; // Name of dataset
  string description = 2; // Description/Explaination/Notes
  string program_element = 3; // Need more info
  bool sensitive_statistical_info = 4; // Contain SSI
  bool has_personal_identifiers = 5; // Has personal IDs
  bool has_data_dictionary = 6; // Always true in the case of a Artemis Dataset
  bool has_record_layout = 7; // Always true in the case of a Artemis Dataset
  bool has_other_supporting_documentation = 8; // Has other supporting documentation
  int32 dataset_size = 9; // Total Size of all partitions in Dataset
  DatasetSizeType dataset_size_type = 10; // The unit type the size is measured in
  repeated string expected_medium = 11; // What's Medium Type?
  DataHoldingDetail data_holding_detail = 12; // Additional info on Data Holdings
  ProvisionAgreement provision_agreement = 13; //Provision Agreement

  repeated string usage = 14; // Usage of dataset, multiple purposes allowed
  string permission = 15; // Currently is a string field (Maybe add a message User, and make permission a repeated list of User ID, or User Group)
  string provider = 16; // Person, organization, or service that provide the raw data
  ProviderType provider_type = 17; //External, internal, or custodian
}

enum DatasetSizeType {
  BYTE = 0; // Byte
  KB = 1; // Kilo Byte
  MB = 2; // Mega Byte
  GB = 3; // Giga Byte
  TB = 4; // Tera Byte
  PB = 5; // Peta Byte
  EB = 6; // Exa Byte
}

enum ProviderType {
  EXTERNAL_PROVIDER = 0; // Other government agencies or organizations
  INTERNAL_PROVIDER = 1; // Fields/Divisions within Statistics Canada
  CUSTODIAN = 2; // Person responsible looking after the dataset
}

/**
 * Entities that is comprised of data
 */
message DataAsset {
  string description = 1;
  string reference_period = 2;
  string granularity_type = 3; // Need more information on Granularity Type
  string state = 5; // Need more information on Data Asset State Type
  google.protobuf.Timestamp last_updated = 6; // Time that the dataset is modified, or used to produce other datasets
  google.protobuf.Timestamp creation_time = 7; // Dataset creation time
  string data_asset_category = 8; // Need more information
  DataRetention data_retention = 9; // Policies of persistent data and record management
  // List of counts on files
  int32 table_count = 10;
  int32 file_count = 11;
  int32 partition_count = 12;
  int32 job_count = 13;
  int32 hists_count = 14;
  int32 parent_count = 15;
  int32 children_count = 20;
}

/**
 * Policies of persistent data and record management
 */
message DataRetention {
  string description = 1;
  string period = 2; // Will different tables in one dataset have different retention periods?
  string retention_trigger_date = 3;
  string retention_trigger = 4; // Need more information on Retention Trigger Type
  string type = 5; // Need more information on Retention Type
}

/**
 * Additional information on data holding
 */
message DataHoldingDetail {
  string receptionFrequency = 4; // Tracked in Table Schema, will different tables in one dataset have different reception frequencies?
  string acquisition_stage = 1; // Stage of acquisition
  float acquisition_cost = 2; // What's acquisition cost?
  bool quality_evaluation_done_on_input = 3; // Quality evaluation on input
}

message ProvisionAgreement {
  string channel = 1; // Need more information on Channel Type
  repeated string statcan_act_section = 2; // Section in Statcan Act
  string channel_detail = 3; // What is a channel?
  string data_usage_type = 4; // Need more information on Data Usage Agreement Type
  string data_acquisition_type = 5; // Need more information on Data Acquisition Type
}

/**
 * Stores list of fields
 */
message TableObjectInfo {
  repeated string fields = 1;
}

/**
 * Required for registering a dataset
 */
message Transform {
  CronusObject menu = 1;
  CronusObject config = 2;
}

/**
 * File type for input data
 */
enum FileType {
  NONE = 0;
  CSV = 1;
  FWF = 2;
  JSON = 3;
  PARQUET = 4;
  ARROW = 5;
  ARROW_STREAM = 6;
  SAS7BDAT = 7;
}

/**
 * Stores file information
 */
message FileObjectInfo {
  FileObjectAuxInfo aux = 1; // Additional information
  FileType type = 2; // File type for input data
  int64 size_bytes = 3; // File size measured in bytes
  string size_unit = 6; // Would be fixed to bytes unless there are size unit required
  repeated Block blocks = 4; // Data are broken down to blocks when storing
  string partition = 5; // Corresponding partition
}

/**
 * Stores file additional information
 */
message FileObjectAuxInfo {
  string description = 1; // A description of the file
  int32 num_columns = 2; // Number of columns in file
  int32 num_rows = 3; // Number of rows in file
  int32 num_batches = 4; // Number of record batches in file

}

/**
 * Stores block information, currently not in use
 */
message Block {
  int32 index = 1;
  BlockInfo info = 2;
}

/**
 * Stores block additional information, currently not in use
 */
message BlockInfo {
  int64 size_bytes = 1;
  int64 offset = 2;
  int64 length = 3;
}

/**
 * Dummy protobuf acting as a real payload to write to storage
 * Given a CronusObject content addressed
 */
message DummyMessage {
  string name = 1;
  string description = 2;
}





